{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T14:30:14.296686Z",
     "start_time": "2021-07-12T14:30:12.857378Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# std\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# datasets\n",
    "import STRING\n",
    "import MINT\n",
    "import bioGRID\n",
    "import HuRI\n",
    "\n",
    "# my lib\n",
    "import PPILinkPred as pred\n",
    "import helper as hr\n",
    "import genData_helper as helper\n",
    "import traversalHelper as tr\n",
    "\n",
    "class ns:\n",
    "    BRToRelat = tr.Helper.binary_to_relation\n",
    "    toDualBR = tr.Helper.to_dual_binary_relation\n",
    "    BRToNode = tr.Helper.binary_relation_to_node\n",
    "    arr_pStr = tr.Helper.list_to_pathStrs\n",
    "    pStr_arr = tr.Helper.pathStrs_to_list\n",
    "    br_str = tr.Helper.br_to_pathStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random PPI Samples from Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T11:37:13.699149Z",
     "start_time": "2021-04-29T11:37:12.691219Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset: HuRI\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 50% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [HuRI.parse_HuRI(root=\"../\")]\n",
    "names = ['HuRI']\n",
    "\n",
    "for n in range(len(names)):\n",
    "    df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:02.153289Z",
     "start_time": "2021-05-14T07:24:51.285401Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset: HuRI\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 55-90% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [HuRI.parse_HuRI(root=\"../\")]\n",
    "names = ['HuRI']\n",
    "\n",
    "for randSz in range(95, 54, -5):\n",
    "    for n in range(len(names)):\n",
    "        df = import_funcs[n]\n",
    "        ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "        sampledPPIs = [rn.sample(ppi, int(len(ppi)*(randSz*0.01))) for i in range(10)]\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(names[n], randSz), \"w\") as f:\n",
    "            f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T11:37:31.255972Z",
     "start_time": "2021-04-29T11:37:13.701151Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human datasets\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "names = ['bioGRID_human', \"STRING_human\", \"MINT_human\"]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    _, df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:29:35.384163Z",
     "start_time": "2021-05-14T07:26:27.628592Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human datasets\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "names = ['bioGRID_human', \"STRING_human\", \"MINT_human\"]\n",
    "\n",
    "for randSz in range(95, 54, -5):\n",
    "    for n in range(len(names)):\n",
    "        _, df = import_funcs[n]\n",
    "        ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "        sampledPPIs = [rn.sample(ppi, int(len(ppi)*(randSz*0.01))) for i in range(10)]\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(names[n], randSz), \"w\") as f:\n",
    "            f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:21:57.363558Z",
     "start_time": "2021-05-06T16:20:47.609083Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset\n",
    "# sample non-PPIs of real-PPIs size\n",
    "\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "completePPIs_map = [\n",
    "    [list(ppi) for ppi in np.asarray([*import_funcs[0]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[1]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[2]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray(HuRI.parse_HuRI(root=\"../\")[['nodeA', 'nodeB']])]\n",
    "]\n",
    "ppi_ds = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for ds in ppi_ds:\n",
    "    ppi = ppi_ds[ds]\n",
    "    validNodes = list(ns.BRToNode(ppi))\n",
    "    ppi_str = set(ns.arr_pStr(ns.toDualBR(ppi)))\n",
    "    ppiNumDoub = len(validNodes)*len(validNodes)-1\n",
    "\n",
    "    sampled_nonPPIs = []\n",
    "    for i in range(10):\n",
    "        candidatePPIs = set()\n",
    "        while len(candidatePPIs) < len(ppi):\n",
    "            rnPPI_i = rn.randint(0, ppiNumDoub)\n",
    "            nodeA, nodeB = validNodes[math.floor(rnPPI_i/len(validNodes))], validNodes[rnPPI_i%len(validNodes)]\n",
    "            if nodeA == nodeB: continue\n",
    "            rnPPI = [nodeA, nodeB]\n",
    "            rnPPI_str, rnPPI_str_rev = ns.br_str(rnPPI), ns.br_str(rnPPI[::-1])\n",
    "            if rnPPI_str in ppi_str or rnPPI_str_rev in candidatePPIs or rnPPI_str in candidatePPIs: continue\n",
    "            candidatePPIs.add(rnPPI_str)\n",
    "        sampled_nonPPIs.append(ns.pStr_arr(list(candidatePPIs)))\n",
    "    \n",
    "    with open(\"./sampled_datasets/{}_sampled_nonPPIs.json\".format(ds), \"w\") as f:\n",
    "        f.write(json.dumps(sampled_nonPPIs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T13:40:24.885585Z",
     "start_time": "2021-05-01T03:48:18.938103Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['HuRI', 'MINT_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    # read dataset\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "\n",
    "    # do link prediction & save results\n",
    "    for method in methods:\n",
    "        for i in range(len(samplePPIs)):\n",
    "            saveFilename = \"{}_{}_sample_{}\".format(method, ds_name, i)\n",
    "            startTime = time.time()\n",
    "            \n",
    "            # jupyter notebook cannot display multi core logging, do it only in terminal\n",
    "            predPPI, predScore = pred.multiCore_PPILinkPred(samplePPIs[i]\n",
    "                                                            , method, coreNo=14, logging=False)\n",
    "            helper.write_runTime(saveFilename, time.time()-startTime)\n",
    "            helper.write_resultData(predPPI, predScore, saveFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"Sim\", \"L3E1_f1\", 'L3E1_f2', 'random']\n",
    "# skip CH2 and L3E1_f2 first because waste time, may use HPC\n",
    "ds_names = ['HuRI', 'MINT_human']\n",
    "\n",
    "for randSz in range(60, 100, 10):\n",
    "    for ds_name in ds_names:\n",
    "        # read dataset\n",
    "        samplePPIs = []\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "            samplePPIs = json.loads(f.read())\n",
    "\n",
    "        # do link prediction & save results\n",
    "        for method in methods:\n",
    "            print(randSz, ds_name, method)\n",
    "            for i in range(len(samplePPIs)):\n",
    "                saveFilename = \"{}_{}_sample_{}_randSz{}Percent\".format(method, ds_name, i, randSz)\n",
    "                startTime = time.time()\n",
    "\n",
    "                # jupyter notebook cannot display multi core logging, do it only in terminal\n",
    "                predPPI, predScore = pred.multiCore_PPILinkPred(samplePPIs[i]\n",
    "                                                                , method, coreNo=14, logging=False)\n",
    "                helper.write_runTime(saveFilename, time.time()-startTime)\n",
    "                helper.write_resultData(predPPI, predScore, saveFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:27:41.695646Z",
     "start_time": "2021-06-30T15:19:54.618632Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# randomly choose n edges, n = size of sampled dataset\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "\n",
    "for randSz in range(50, 100, 10):\n",
    "    for ds_name in ds_names:\n",
    "        samplePPIs = []\n",
    "        if randSz == 50:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        else:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        sampleSize = len(samplePPIs[0])\n",
    "        sampleSize = int(sampleSize/(randSz/100)*np.around(1-randSz/100, 2))\n",
    "\n",
    "        # loop each method, each trial, extract the number into one json\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            samplePPIbr = samplePPIs[trial]\n",
    "            sampleNodes = list(ns.BRToNode(samplePPIbr))\n",
    "            samplePPIbr_str = set(ns.arr_pStr(ns.toDualBR(samplePPIbr)))\n",
    "            ppiNumDoub = len(sampleNodes)*len(sampleNodes)-1\n",
    "\n",
    "            candidatePPIs = set()\n",
    "            while len(candidatePPIs) < sampleSize:\n",
    "                rnPPI_i = rn.randint(0, ppiNumDoub)\n",
    "                nodeA, nodeB = sampleNodes[math.floor(rnPPI_i/len(sampleNodes))], sampleNodes[rnPPI_i%len(sampleNodes)]\n",
    "                if nodeA == nodeB: continue\n",
    "                rnPPI = [nodeA, nodeB]\n",
    "                rnPPI_str, rnPPI_str_rev = ns.br_str(rnPPI), ns.br_str(rnPPI[::-1])\n",
    "                if rnPPI_str in samplePPIbr_str or rnPPI_str_rev in candidatePPIs or rnPPI_str in candidatePPIs: continue\n",
    "                candidatePPIs.add(rnPPI_str)\n",
    "\n",
    "            fullPPIs.append(ns.pStr_arr(candidatePPIs))\n",
    "            fullScores.append([1 for i in range(sampleSize)])\n",
    "        \n",
    "        if randSz == 50:\n",
    "            with open(\"./linkPred_out_reduced/random_{}_topPPI.json\".format(ds_name), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/random_{}_topScore.json\".format(ds_name), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))\n",
    "        else:\n",
    "            with open(\"./linkPred_out_reduced/random_{}_randSz{}_topPPI.json\".format(ds_name, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/random_{}_randSz{}_topScore.json\".format(ds_name, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bioGRID, STRING Human Dataset are generated using generate_prediction_HPC.py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for Analysis & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T08:11:19.547376Z",
     "start_time": "2021-05-29T08:11:15.625847Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract only top n edges, n = size of sampled dataset\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['bioGRID_human', 'STRING_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    sampleSize = 0\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        sampleSize = len(json.loads(f.read())[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        for trial in range(10):\n",
    "            topPPIs, topScores = [], []\n",
    "            for core in range(24):\n",
    "                with open(\"./linkPred_human_out/{}_{}_sample_{}_c{}_PPI.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topPPIs += json.loads(f.read())\n",
    "                with open(\"./linkPred_human_out/{}_{}_sample_{}_c{}_score.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topScores += json.loads(f.read())\n",
    "                topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "            \n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topPPIs))\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T08:11:19.548376Z",
     "start_time": "2021-05-29T08:11:15.743Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['STRING_human', 'bioGRID_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    for method in methods:\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPIs.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScores.append(json.loads(f.read()))\n",
    "                \n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPIs))\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T19:36:00.203276Z",
     "start_time": "2021-05-01T16:24:34.002351Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# extract only top n edges, n = size of sampled dataset\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"L3E1_f1\", \"L3E1_f2\", \"L3E4_f1\", \"L3E4_f2\", \"Sim\"]\n",
    "ds_names = ['MINT_human', 'HuRI']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    sampleSize = len(samplePPIs[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        fullPPI, fullScore = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_human_out/{}_{}_sample_{}_PPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPI.append(json.loads(f.read())[0:sampleSize])\n",
    "            with open(\"./linkPred_human_out/{}_{}_sample_{}_score.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScore.append(json.loads(f.read())[0:sampleSize])\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPI))\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T15:36:08.786790Z",
     "start_time": "2021-06-22T15:36:08.771784Z"
    }
   },
   "outputs": [],
   "source": [
    "allPaths = [\"I:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"E:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"D:/research offline repo/ppiLPred_BMC/notebook\"\n",
    "            , \"G:/research/ppiLPred_BMC/notebook\"]\n",
    "coreNo, trialNum = 12, 10\n",
    "def verify(method, ds, randSz):\n",
    "    # check HPC or not\n",
    "    isHPC = None\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(\n",
    "            method, ds, randSz)): return 0, None, None\n",
    "        \n",
    "        if os.path.exists(\"{}/linkPred_out/{}_{}_sample_9_randSz{}Percent_c0_PPI.json\".format(\n",
    "            path, method, ds, randSz)):\n",
    "            isHPC = True\n",
    "            break\n",
    "        elif os.path.exists(\"{}/linkPred_out/{}_{}_sample_9_randSz{}Percent_PPI.json\".format(\n",
    "            path, method, ds, randSz)):\n",
    "            isHPC = False\n",
    "            break\n",
    "            \n",
    "    if isHPC is None: return 2, None, None\n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    if isHPC:\n",
    "        for trial in range(trialNum):\n",
    "            for core in range(coreNo):\n",
    "                for path in allPaths:\n",
    "                    filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_c{}_PPI.json\".format(\n",
    "                        path, method, ds, trial, randSz, core)\n",
    "                    if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    else:\n",
    "        for trial in range(trialNum):\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_PPI.json\".format(\n",
    "                    path, method, ds, trial, randSz)\n",
    "                if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, isHPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T08:37:58.247038Z",
     "start_time": "2021-05-30T05:50:28.681688Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 bioGRID_human commonNeighbor None 0\n",
      "50 bioGRID_human L3Normalizing None 0\n",
      "50 bioGRID_human CRA None 0\n",
      "50 bioGRID_human CH2_L3 None 0\n",
      "50 bioGRID_human Sim None 0\n",
      "50 bioGRID_human random None 0\n",
      "50 bioGRID_human L3E1_f1 None 0\n",
      "50 bioGRID_human L3E1_f2 None 0\n",
      "50 STRING_human commonNeighbor None 0\n",
      "50 STRING_human L3Normalizing None 0\n",
      "50 STRING_human CRA None 0\n",
      "50 STRING_human CH2_L3 True 1\n",
      "50 STRING_human Sim True 1\n",
      "50 STRING_human random None 0\n",
      "50 STRING_human L3E1_f1 True 1\n",
      "50 STRING_human L3E1_f2 True 1\n"
     ]
    }
   ],
   "source": [
    "allPaths = [\"I:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"E:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"D:/research offline repo/ppiLPred_BMC/notebook\"\n",
    "            , \"G:/research/ppiLPred_BMC/notebook\"]\n",
    "coreNo, trialNum = 24, 10\n",
    "def verify_tmp(method, ds):\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(\n",
    "            method, ds)): return 0, None, None\n",
    "            \n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    for trial in range(trialNum):\n",
    "        for core in range(coreNo):\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_c{}_PPI.json\".format(\n",
    "                    path, method, ds, trial, core)\n",
    "                if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, True\n",
    "\n",
    "# trim data that isn't trimmed yet\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", 'random', \"L3E1_f1\", \"L3E1_f2\"]\n",
    "dss = ['bioGRID_human', 'STRING_human']\n",
    "coreNo, trialNum = 24, 10\n",
    "\n",
    "for ds in dss:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    sampleSize = len(samplePPIs[0])\n",
    "\n",
    "    for method in methods:\n",
    "        available, filenames, isHPC = verify_tmp(method, ds)\n",
    "        print(50, ds, method, isHPC, available)\n",
    "        if available != 1: continue\n",
    "            \n",
    "        for trial in range(trialNum):\n",
    "            topPPIs, topScores = [], []\n",
    "            for core in range(coreNo):\n",
    "                with open(filenames[trial*coreNo+core]+\"_PPI.json\", \"r\") as f: topPPIs += json.loads(f.read())\n",
    "                with open(filenames[trial*coreNo+core]+\"_score.json\", \"r\") as f: topScores += json.loads(f.read())\n",
    "                topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topPPIs))\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topScores))\n",
    "\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds, trial), \"r\") as f:\n",
    "                fullPPIs.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds, trial), \"r\") as f:\n",
    "                fullScores.append(json.loads(f.read()))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPIs))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topScore.json\".format(method, ds), \"w\") as f:\n",
    "            f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:17:15.354100Z",
     "start_time": "2021-06-22T15:38:11.675766Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 bioGRID_human L3E1_f2 True 1\n",
      "80 bioGRID_human CH2_L3 True 1\n",
      "80 STRING_human L3E1_f2 True 1\n",
      "80 STRING_human CH2_L3 True 1\n",
      "90 bioGRID_human L3E1_f2 True 1\n",
      "90 bioGRID_human CH2_L3 True 1\n",
      "90 STRING_human L3E1_f2 True 1\n",
      "90 STRING_human CH2_L3 True 1\n"
     ]
    }
   ],
   "source": [
    "# trim data that isn't trimmed yet\n",
    "methods = [\"L3E1_f2\", \"CH2_L3\"]\n",
    "dss = ['bioGRID_human', 'STRING_human']\n",
    "coreNo, trialNum = 24, 10\n",
    "\n",
    "# assume rawData complete\n",
    "def verify_tmp(method, ds, randSz):\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(\n",
    "            method, ds, randSz)): return 0, None, None\n",
    "            \n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    for trial in range(trialNum):\n",
    "        for core in range(coreNo):\n",
    "            noFile = 0\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_c{}_PPI.json\".format(\n",
    "                    path, method, ds, trial, randSz, core)\n",
    "                if os.path.exists(filename):\n",
    "                    filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "                else:\n",
    "                    noFile += 1\n",
    "            if noFile == len(allPaths): break\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, True\n",
    "\n",
    "for randSz in range(80, 91, 10):\n",
    "    for ds in dss:\n",
    "        samplePPIs = []\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds, randSz), \"r\") as f:\n",
    "            samplePPIs = json.loads(f.read())\n",
    "        sampleSize = len(samplePPIs[0])\n",
    "        sampleSize = int(sampleSize/(randSz/100)*np.around(1-randSz/100, 2))\n",
    "\n",
    "        for method in methods:\n",
    "            available, filenames, isHPC = verify_tmp(method, ds, randSz)\n",
    "            print(randSz, ds, method, isHPC, available)\n",
    "            if available != 1: continue\n",
    "\n",
    "            for trial in range(trialNum):\n",
    "                topPPIs, topScores = [], []\n",
    "                relatedFiles = [file for file in filenames if \"sample_\"+str(trial) in file]\n",
    "                for file in relatedFiles:\n",
    "                    with open(file+\"_PPI.json\", \"r\") as f: topPPIs += json.loads(f.read())\n",
    "                    with open(file+\"_score.json\", \"r\") as f: topScores += json.loads(f.read())\n",
    "                    topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                    topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topPPI.json\".format(method, ds, trial, randSz), \"w\") as f:\n",
    "                    f.write(json.dumps(topPPIs))\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topScore.json\".format(method, ds, trial, randSz), \"w\") as f:\n",
    "                    f.write(json.dumps(topScores))\n",
    "\n",
    "            fullPPIs, fullScores = [], []\n",
    "            for trial in range(10):\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topPPI.json\".format(method, ds, trial, randSz), \"r\") as f:\n",
    "                    fullPPIs.append(json.loads(f.read()))\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topScore.json\".format(method, ds, trial, randSz), \"r\") as f:\n",
    "                    fullScores.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(method, ds, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topScore.json\".format(method, ds, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GOSemSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run **GOSemSim_compute.R** of the same directory, it scans ./linkPred_out and output GOSemSim in the same format of **xxx_topScore.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate precision recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:29:11.111040Z",
     "start_time": "2021-06-23T10:10:07.029755Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# for each dataset & predictor, get precision recall and save in one file for each trial\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "completePPIs_map = [\n",
    "    [list(ppi) for ppi in np.asarray([*import_funcs[0]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[1]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[2]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray(HuRI.parse_HuRI(root=\"../\")[['nodeA', 'nodeB']])]\n",
    "]\n",
    "completePPIs = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for randSz in range(50, 91, 10):\n",
    "    for ds_name in ds_names:\n",
    "        samplePPIs = []\n",
    "        if randSz != 50:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        else:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "\n",
    "\n",
    "        for method in methods:\n",
    "            fullPPIs = []\n",
    "            \n",
    "            if randSz != 50:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(method, ds_name, randSz), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_randSz{}_topPPI_{}\".format(method, ds_name, randSz, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "            else:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_topPPI_{}\".format(method, ds_name, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "\n",
    "            for key in precRecMap:\n",
    "                with open(\"./precision_recall_out/{}.json\".format(key), 'w') as f:\n",
    "                    f.write(json.dumps(precRecMap[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
